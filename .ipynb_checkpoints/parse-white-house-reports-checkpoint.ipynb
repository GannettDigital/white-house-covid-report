{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from pyquery import PyQuery as pq\n",
    "import simplejson as json\n",
    "from tqdm import tqdm\n",
    "# import pandas as pd     # so so so so so slow\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "reportdir = \"/var/www/html/misc/20200417-covid-county-analysis/\"   # Blank or ending in a slash\n",
    "if not os.path.exists(reportdir):\n",
    "    reportdir = \"\"\n",
    "\n",
    "xlsxdir = \"xlsx/\"\n",
    "csvdir = \"csv/\"\n",
    "summarydir = reportdir + \"white-house-reports/\"\n",
    "\n",
    "for targetdir in [xlsxdir, csvdir, summarydir]:\n",
    "    os.makedirs(targetdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"https://healthdata.gov\"\n",
    "starturl = \"https://healthdata.gov/Health/COVID-19-Community-Profile-Report/gqxm-d9w9\"\n",
    "r = requests.get(starturl)\n",
    "html = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the right JSON object\n",
    "for row in html.splitlines():\n",
    "    if '{\"view\":' in row:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = json.loads(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab just what we want\n",
    "entries = rawdata['view']['attachments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 525/525 [00:00<00:00, 834.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 new file(s) found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "newfiles = 0\n",
    "for entry in tqdm(entries):\n",
    "    basefilename = entry['name']\n",
    "    if \".xlsx\" in basefilename:   # Get just the Excel files\n",
    "        targetfilename = xlsxdir + basefilename\n",
    "        if not os.path.exists(targetfilename):    # if we haven't already downloaded this\n",
    "            filedate = basefilename.split(\"_\")[-2]\n",
    "            if not os.path.exists(csvdir + filedate + \".csv\"):    # If we don't have the CSV either\n",
    "                targeturl = baseurl + entry['href']\n",
    "                r = requests.get(targeturl)\n",
    "                if r.status_code != 200:\n",
    "                    print(f\"Error downloading {basefilename} from {targeturl}\")\n",
    "                else:\n",
    "                    with open(targetfilename, \"wb\") as outfile:\n",
    "                        outfile.write(r.content)\n",
    "                    newfiles += 1\n",
    "print(f\"{newfiles} new file(s) found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 263/263 [35:53<00:00,  8.19s/it]\n"
     ]
    }
   ],
   "source": [
    "if newfiles > 0:     # If we need to reparse everything:\n",
    "    excelfiles = glob(xlsxdir + \"*.xlsx\")\n",
    "    for excelfilename in tqdm(excelfiles):\n",
    "        filedate = excelfilename.split(\"_\")[-2]\n",
    "        csvfilename = csvdir + filedate + \".csv\"\n",
    "        if not os.path.exists(csvfilename):\n",
    "            workbook = load_workbook(filename=excelfilename)\n",
    "            countytab = workbook[\"Counties\"]\n",
    "            with open(csvfilename, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "                writer = csv.writer(outfile)\n",
    "                for entry in list(countytab.iter_rows(values_only=True))[1:]:   # Skip first row\n",
    "                    writer.writerow(list(entry))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 263/263 [00:24<00:00, 10.80it/s]\n"
     ]
    }
   ],
   "source": [
    "if newfiles > 0:     # If we need to reparse everything:\n",
    "    masterdict = {}\n",
    "    csvfiles = list(sorted(glob(csvdir + \"*.csv\")))\n",
    "    for filenumber, csvfilename in enumerate(tqdm(csvfiles)):\n",
    "        basefilename = csvfilename.replace(\"\\\\\", \"/\").replace(csvdir, \"\")\n",
    "        filedate = basefilename.replace(\".csv\", \"\")\n",
    "        with open(csvfilename, \"r\", encoding=\"utf-8\") as infile:\n",
    "            reader = csv.DictReader(infile)\n",
    "            for row in reader:\n",
    "                fips = row['FIPS code'].zfill(5)\n",
    "                state = row['State Abbreviation']\n",
    "                county = row['County']\n",
    "                cases = row['Cumulative cases']\n",
    "                deaths = row['Cumulative deaths']\n",
    "                if cases == \"\":\n",
    "                    cases = 0\n",
    "                else:\n",
    "                    cases = int(cases)\n",
    "                if deaths == \"\":\n",
    "                    deaths = 0\n",
    "                else:\n",
    "                    deaths = int(deaths)\n",
    "                if state not in masterdict:\n",
    "                    masterdict[state] = {}\n",
    "                if fips not in masterdict[state]:\n",
    "                    masterdict[state][fips] = {}\n",
    "                line = {\n",
    "                    \"fips\": fips,\n",
    "                    \"state\": state,\n",
    "                    \"county\": county,\n",
    "                    \"filedate\": filedate,\n",
    "                    \"cases\": cases,\n",
    "                    \"deaths\": deaths\n",
    "                }\n",
    "                masterdict[state][fips][filedate] = line   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 52/52 [00:01<00:00, 27.96it/s]\n"
     ]
    }
   ],
   "source": [
    "if newfiles > 0:     # If we need to reparse everything:masterdict = {}\n",
    "    headers = list(masterdict[state][fips][filedate].keys())\n",
    "    for state in tqdm(masterdict):\n",
    "        with open(summarydir + state + \".csv\", \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            writer.writerow(headers)\n",
    "            for fips in sorted(masterdict[state]):\n",
    "                for filedate in masterdict[state][fips]:\n",
    "                    writer.writerow(list(masterdict[state][fips][filedate].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
