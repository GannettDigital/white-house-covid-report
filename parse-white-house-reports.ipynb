{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import simplejson as json\n",
    "from tqdm import tqdm\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "import csv\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If reports don't land in a specific spot on the web server, or a related project folder,\n",
    "# assume reports should land in a subfolder of the current directory\n",
    "\n",
    "reportdir = \"/var/www/html/misc/20200417-covid-county-analysis/\"   # Blank or ending in a slash\n",
    "if not os.path.exists(reportdir):\n",
    "    reportdir = \"../covid-counties-analysis/\"\n",
    "    if not os.path.exists(reportdir):\n",
    "        reportdir = \"\"\n",
    "\n",
    "xlsxdir = \"xlsx/\"\n",
    "csvdir = \"csv/\"\n",
    "summarydir = reportdir + \"white-house-reports/\"\n",
    "ignoredir = reportdir + \"ignore/\"\n",
    "highlightsfile = ignoredir + \"white-house-latest.json\"\n",
    "\n",
    "for targetdir in [xlsxdir, csvdir, summarydir, ignoredir]:\n",
    "    os.makedirs(targetdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "baseurl = \"https://healthdata.gov\"\n",
    "starturl = \"https://healthdata.gov/Health/COVID-19-Community-Profile-Report/gqxm-d9w9\"\n",
    "r = requests.get(starturl)\n",
    "html = r.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the right JSON object\n",
    "for row in html.splitlines():\n",
    "    if '{\"view\":' in row:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawdata = json.loads(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab just what we want\n",
    "entries = rawdata['view']['attachments']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 736/736 [00:00<00:00, 9184.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Old basefilename: Community_Profile_Report_20220207.xlsx\n",
      "New basefilename: Community_Profile_Report_20220207_Public.xlsx\n",
      "0 new file(s) found\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "newfiles = 0\n",
    "for entry in tqdm(entries):\n",
    "    basefilename = entry['name']\n",
    "    if \".xlsx\" in basefilename:   # Get just the Excel files\n",
    "        if \" \" in basefilename:    # sample: 'Community Profile Report 20220207.xlsx'\n",
    "            print(f\"Old basefilename: {basefilename}\")\n",
    "            keydate = basefilename.split(\" \")[-1].split(\".xlsx\")[0]\n",
    "            basefilename = f\"Community_Profile_Report_{keydate}_Public.xlsx\"\n",
    "            print(f\"New basefilename: {basefilename}\")\n",
    "        if \"Public\" not in basefilename:\n",
    "            print(f\"Old basefilename: {basefilename}\")\n",
    "            basefilename = basefilename.replace(\".xlsx\", \"_Public.xlsx\")                \n",
    "            print(f\"New basefilename: {basefilename}\")\n",
    "        targetfilename = xlsxdir + basefilename\n",
    "        if \"_P_\" not in targetfilename:\n",
    "            if not os.path.exists(targetfilename):    # if we haven't already downloaded this\n",
    "                filedate = basefilename.split(\"_\")[-2]\n",
    "                if not os.path.exists(csvdir + filedate + \".csv\"):    # If we don't have the CSV either\n",
    "                    targeturl = baseurl + entry['href']\n",
    "                    r = requests.get(targeturl)\n",
    "                    if r.status_code != 200:\n",
    "                        print(f\"Error downloading {basefilename} from {targeturl}\")\n",
    "                    else:\n",
    "                        with open(targetfilename, \"wb\") as outfile:\n",
    "                            outfile.write(r.content)\n",
    "                        newfiles += 1\n",
    "print(f\"{newfiles} new file(s) found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No new files found. Stopping.\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Python37\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3426: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if newfiles == 0:\n",
    "    print(\"No new files found. Stopping.\")\n",
    "    sys.exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelfiles = glob(xlsxdir + \"*.xlsx\")\n",
    "for excelfilename in tqdm(excelfiles):\n",
    "    filedate = excelfilename.split(\"_\")[-2]\n",
    "    csvfilename = csvdir + filedate + \".csv\"\n",
    "    if not os.path.exists(csvfilename):\n",
    "        workbook = load_workbook(filename=excelfilename)\n",
    "        countytab = workbook[\"Counties\"]\n",
    "        with open(csvfilename, \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "            writer = csv.writer(outfile)\n",
    "            for entry in list(countytab.iter_rows(values_only=True))[1:]:   # Skip first row\n",
    "                writer.writerow(list(entry))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterdict = {}\n",
    "csvfiles = list(sorted(glob(csvdir + \"*.csv\")))\n",
    "for filenumber, csvfilename in enumerate(tqdm(csvfiles)):\n",
    "    basefilename = csvfilename.replace(\"\\\\\", \"/\").replace(csvdir, \"\")\n",
    "    filedate = basefilename.replace(\".csv\", \"\")\n",
    "    with open(csvfilename, \"r\", encoding=\"utf-8\") as infile:\n",
    "        reader = csv.DictReader(infile)\n",
    "        for row in reader:\n",
    "            fips = row['FIPS code'].zfill(5)\n",
    "            state = row['State Abbreviation']\n",
    "            county = row['County']\n",
    "            cases = row['Cumulative cases']\n",
    "            deaths = row['Cumulative deaths']\n",
    "            if cases == \"\":\n",
    "                cases = 0\n",
    "            else:\n",
    "                cases = int(cases)\n",
    "            if deaths == \"\":\n",
    "                deaths = 0\n",
    "            else:\n",
    "                deaths = int(deaths)\n",
    "            if state not in masterdict:\n",
    "                masterdict[state] = {}\n",
    "            if fips not in masterdict[state]:\n",
    "                masterdict[state][fips] = {}\n",
    "            line = {\n",
    "                \"fips\": fips,\n",
    "                \"state\": state,\n",
    "                \"county\": county,\n",
    "                \"filedate\": filedate,\n",
    "                \"cases\": cases,\n",
    "                \"deaths\": deaths\n",
    "            }\n",
    "            masterdict[state][fips][filedate] = line   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = list(masterdict[state][fips][filedate].keys())\n",
    "for state in tqdm(masterdict):\n",
    "    with open(summarydir + state + \".csv\", \"w\", newline=\"\", encoding=\"utf-8\") as outfile:\n",
    "        writer = csv.writer(outfile)\n",
    "        writer.writerow(headers)\n",
    "        for fips in sorted(masterdict[state]):\n",
    "            for filedate in masterdict[state][fips]:\n",
    "                writer.writerow(list(masterdict[state][fips][filedate].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highlightsdict = {}\n",
    "for state in masterdict:\n",
    "    for fips in masterdict[state]:\n",
    "        localdates = list(sorted(masterdict[state][fips].keys()))\n",
    "        if fips in highlightsdict:\n",
    "            print(f\"FIPS {fips} was repeated somehow.\")\n",
    "        highlightsdict[fips] = masterdict[state][fips][localdates[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = {}\n",
    "for fips in list(sorted(highlightsdict.keys())):\n",
    "    temp[fips] = highlightsdict[fips]\n",
    "highlightsdict = temp\n",
    "temp = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(highlightsfile, \"w\") as outfile:\n",
    "    outfile.write(json.dumps(highlightsdict, indent=\" \" * 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
